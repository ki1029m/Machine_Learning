{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNf1qVRoK8y4htANlt2xson"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_z-FOIl3qrq",
        "outputId": "f0c01d61-28bf-4c77-eadf-f2c33358cfac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n",
            "Epoch 1/20\n",
            "235/235 [==============================] - 2s 4ms/step - loss: 0.6140 - accuracy: 0.7880\n",
            "Epoch 2/20\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.4130 - accuracy: 0.8543\n",
            "Epoch 3/20\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.3678 - accuracy: 0.8696\n",
            "Epoch 4/20\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.3421 - accuracy: 0.8765\n",
            "Epoch 5/20\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.3193 - accuracy: 0.8839\n",
            "Epoch 6/20\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.3031 - accuracy: 0.8905\n",
            "Epoch 7/20\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2939 - accuracy: 0.8939\n",
            "Epoch 8/20\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2802 - accuracy: 0.8969\n",
            "Epoch 9/20\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2729 - accuracy: 0.8986\n",
            "Epoch 10/20\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2652 - accuracy: 0.9027\n",
            "Epoch 11/20\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2531 - accuracy: 0.9059\n",
            "Epoch 12/20\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2466 - accuracy: 0.9084\n",
            "Epoch 13/20\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2396 - accuracy: 0.9120\n",
            "Epoch 14/20\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2323 - accuracy: 0.9144\n",
            "Epoch 15/20\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2273 - accuracy: 0.9150\n",
            "Epoch 16/20\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2193 - accuracy: 0.9198\n",
            "Epoch 17/20\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2144 - accuracy: 0.9204\n",
            "Epoch 18/20\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2108 - accuracy: 0.9213\n",
            "Epoch 19/20\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2037 - accuracy: 0.9251\n",
            "Epoch 20/20\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1996 - accuracy: 0.9263\n",
            "Model 0th accuracy: 88.49999904632568\n",
            "Baseline (average) accuracy: 88.49999904632568\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_15 (Dense)            (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109,386\n",
            "Trainable params: 109,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "235/235 [==============================] - 9s 28ms/step - loss: 0.7781 - accuracy: 0.7315\n",
            "Epoch 2/20\n",
            "235/235 [==============================] - 6s 28ms/step - loss: 0.4647 - accuracy: 0.8389\n",
            "Epoch 3/20\n",
            "235/235 [==============================] - 7s 28ms/step - loss: 0.3945 - accuracy: 0.8630\n",
            "Epoch 4/20\n",
            "235/235 [==============================] - 6s 28ms/step - loss: 0.3495 - accuracy: 0.8789\n",
            "Epoch 5/20\n",
            "235/235 [==============================] - 7s 28ms/step - loss: 0.3184 - accuracy: 0.8892\n",
            "Epoch 6/20\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.2968 - accuracy: 0.8962\n",
            "Epoch 7/20\n",
            "235/235 [==============================] - 7s 28ms/step - loss: 0.2809 - accuracy: 0.8999\n",
            "Epoch 8/20\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.2694 - accuracy: 0.9051\n",
            "Epoch 9/20\n",
            "235/235 [==============================] - 6s 28ms/step - loss: 0.2539 - accuracy: 0.9103\n",
            "Epoch 10/20\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.2454 - accuracy: 0.9129\n",
            "Epoch 11/20\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.2290 - accuracy: 0.9173\n",
            "Epoch 12/20\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.2231 - accuracy: 0.9190\n",
            "Epoch 13/20\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.2174 - accuracy: 0.9226\n",
            "Epoch 14/20\n",
            "235/235 [==============================] - 7s 28ms/step - loss: 0.2067 - accuracy: 0.9263\n",
            "Epoch 15/20\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.2010 - accuracy: 0.9277\n",
            "Epoch 16/20\n",
            "235/235 [==============================] - 7s 28ms/step - loss: 0.1927 - accuracy: 0.9301\n",
            "Epoch 17/20\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.1852 - accuracy: 0.9336\n",
            "Epoch 18/20\n",
            "235/235 [==============================] - 7s 28ms/step - loss: 0.1853 - accuracy: 0.9324\n",
            "Epoch 19/20\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.1759 - accuracy: 0.9364\n",
            "Epoch 20/20\n",
            "235/235 [==============================] - 7s 28ms/step - loss: 0.1701 - accuracy: 0.9380\n",
            "Model 0th accuracy: 92.11999773979187\n",
            "Proposed (average) accuracy: 92.11999773979187\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 28, 28, 64)        320       \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 28, 28, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 14, 14, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 14, 14, 128)       32896     \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 14, 14, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 7, 7, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 6272)              0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 128)               802944    \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 845,834\n",
            "Trainable params: 845,450\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n",
            "SUCCESS! Difference: 3.620\n",
            "TF 2.12.0 under GPU True\n",
            "python version 3.9.16 (main, Dec  7 2022, 01:11:51) \n",
            "[GCC 9.4.0]\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "#!pip install tensorflow-determinism\n",
        "\n",
        "import os\n",
        "####*IMPORANT*: Have to do this line *before* importing tensorflow\n",
        "os.environ['PYTHONHASHSEED']=str(1)\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout,BatchNormalization \n",
        "from tensorflow.keras.optimizers import SGD,Adam,Adagrad,RMSprop\n",
        "print(tf.__version__)\n",
        "\n",
        "### WARN: Must have ###\n",
        "# to make this notebook's output stable across runs\n",
        "def reset_random_seeds():\n",
        "   os.environ['PYTHONHASHSEED']=str(1)\n",
        "   tf.random.set_seed(1)\n",
        "   np.random.seed(1)\n",
        "   random.seed(1)\n",
        "   os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "   \n",
        "# fashion MNIST 읽어 와서 신경망에 입력할 형태로 변환\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train = x_train.reshape(60000,784)\n",
        "x_test = x_test.reshape(10000,784)\n",
        "\n",
        "x_train_cnn = x_train.reshape(x_train.shape[0], 28, 28, 1) \n",
        "x_test_cnn = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "\n",
        "x_train=x_train.astype(np.float32)/255.0\n",
        "x_test=x_test.astype(np.float32)/255.0\n",
        "\n",
        "x_train_cnn=x_train_cnn.astype(np.float32)/255.0  \n",
        "x_test_cnn=x_test_cnn.astype(np.float32)/255.0\n",
        "\n",
        "y_train=tf.keras.utils.to_categorical(y_train,10)\n",
        "y_test=tf.keras.utils.to_categorical(y_test,10)\n",
        "\n",
        "\n",
        "# 모델을 설계해주는 함수(모델을 나타내는 객체 model을 반환)\n",
        "def run_model(x_train, y_train):\n",
        "    reset_random_seeds()\n",
        "    model=Sequential()\n",
        "    model.add(Dense(128,activation='relu',input_shape=(784,)))\n",
        "    model.add(Dense(64,activation='relu'))\n",
        "    model.add(Dense(10,activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(),\n",
        "                  metrics=['accuracy'])\n",
        "    model.fit(x_train, y_train, batch_size=256, epochs=20)\n",
        "    return model\n",
        "\n",
        "### Update: 22.04.01\n",
        "acc = 0\n",
        "models = []\n",
        "n_of_models = 1\n",
        "n = 0\n",
        "models.append(run_model(x_train, y_train))\n",
        "print('Model {}th accuracy: {}'.format(n, models[n].evaluate(x_test,y_test,verbose=0)[1]*100))\n",
        "acc =  models[n].evaluate(x_test,y_test,verbose=0)[1]*100\n",
        "\n",
        "g_org_model_acc = acc\n",
        "print('Baseline (average) accuracy: {}'.format(acc))\n",
        "\n",
        "models[0].summary()\n",
        "\n",
        "###################################\n",

        "###################################\n",
        "def run_proposed_model(x_train, y_train):  \n",
        "    reset_random_seeds()  \n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Conv2D(filters = 64, kernel_size = (2,2), padding = 'same', activation = 'relu', input_shape = (28, 28, 1)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "    model.add(Dropout(0.3))\n",
        "    \n",
        "    model.add(Conv2D(filters = 128, kernel_size = (2,2), padding = 'same', activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "    model.add(Dropout(0.3))\n",
        "    \n",
        "    model.add(Flatten()) #Flaatten으로 이미지를 일차원으로 바꿔줌\n",
        "    model.add(Dense(128, activation = 'relu'))\n",
        "    model.add(Dense(64, activation = 'relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation = 'softmax'))\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(),\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    # [※주의] 변경하면 안되는 옵션 : epochs, batch_size, _train, _text\n",
        "    model.fit(x_train, y_train, batch_size=256, epochs=20)\n",
        "    return model\n",
        "\n",
        "### Update: 22.04.01\n",
        "\n",
        "n_of_models = 1  # 실행할 때마다 정확도 변경하는지 확인하고 싶을 때 개수 증가시켜서 확인 가능\n",
        "acc = 0\n",
        "pro_models = []\n",
        "if tf.test.is_gpu_available():\n",
        "  for n in range (0, n_of_models):\n",
        "    pro_models.append(run_proposed_model(x_train_cnn, y_train)) \n",
        "    acc += pro_models[n].evaluate(x_test_cnn,y_test,verbose=0)[1]*100 # verbose=1 when you want to see the progress\n",
        "    print('Model {}th accuracy: {}'.format(n, \n",
        "                                           pro_models[n].evaluate(x_test_cnn,y_test,verbose=0)[1]*100))\n",
        "  acc /= n_of_models\n",
        "else:\n",
        "  n_of_models = 1\n",
        "  n = 0\n",
        "  pro_models.append(run_proposed_model(x_train_cnn, y_train)) \n",
        "  print('Model {}th accuracy: {}'.format(n, \n",
        "                                         pro_models[n].evaluate(x_test_cnn,y_test,verbose=0)[1]*100))\n",
        "  acc =  pro_models[n].evaluate(x_test_cnn,y_test,verbose=0)[1]*100 # verbose=1 when you want to see the progress\n",
        "\n",
        "g_pro_model_acc = acc\n",
        "print('Proposed (average) accuracy: {}'.format(acc))\n",
        "\n",
        "pro_models[0].summary() \n",
        "\n",
        "### Update: 23.03.28\n",
        "#################################\n",
        "# 내가 개선한 모델의 정확률을 기존과 비교하며 출력\n",
        "if g_pro_model_acc > (g_org_model_acc + 0.3):\n",
        "    print('SUCCESS! Difference: {0:0.3f}'.format(\n",
        "                        (g_pro_model_acc - g_org_model_acc)))\n",
        "else:\n",
        "    print('TRY DIFFERENTLY! Difference: {0:0.3f}'.format(\n",
        "                        (g_pro_model_acc - g_org_model_acc)))\n",
        "print('TF {0} under GPU {1}'.format(\n",
        "    tf.__version__, tf.test.is_gpu_available()))\n",
        "import sys\n",
        "print(\"python version\", sys.version)\n",
        "#################################\n",
        "# ★★★ capture the below prints and put them in the report ★★★"
      ]
    }
  ]
}
