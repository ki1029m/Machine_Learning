{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMoLZ12pjgnggBm5uJ4YvBr"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsybPlui2pO9",
        "outputId": "4abc670e-7431-4563-d9c5-86ba5c424185"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reduced train/val size: 50000 4000 input shape: (32, 32, 3)\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_24 (Conv2D)          (None, 30, 30, 64)        1792      \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 15, 15, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 15, 15, 64)        0         \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 15, 15, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 7, 7, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 7, 7, 256)         295168    \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 7, 7, 256)         590080    \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (None, 3, 3, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_11 (Flatten)        (None, 2304)              0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 1000)              2305000   \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 1000)              0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 10)                10010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,275,906\n",
            "Trainable params: 3,275,906\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/70\n",
            "782/782 [==============================] - 12s 13ms/step - loss: 2.0938 - accuracy: 0.2179 - val_loss: 1.8530 - val_accuracy: 0.3370\n",
            "Epoch 2/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.7561 - accuracy: 0.3529 - val_loss: 1.6722 - val_accuracy: 0.3940\n",
            "Epoch 3/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 1.6315 - accuracy: 0.3987 - val_loss: 1.5728 - val_accuracy: 0.4218\n",
            "Epoch 4/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.5479 - accuracy: 0.4335 - val_loss: 1.5477 - val_accuracy: 0.4433\n",
            "Epoch 5/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.4947 - accuracy: 0.4535 - val_loss: 1.4711 - val_accuracy: 0.4778\n",
            "Epoch 6/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.4470 - accuracy: 0.4740 - val_loss: 1.4433 - val_accuracy: 0.4897\n",
            "Epoch 7/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.4080 - accuracy: 0.4900 - val_loss: 1.4134 - val_accuracy: 0.4983\n",
            "Epoch 8/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.3748 - accuracy: 0.5046 - val_loss: 1.3629 - val_accuracy: 0.5153\n",
            "Epoch 9/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.3443 - accuracy: 0.5184 - val_loss: 1.3474 - val_accuracy: 0.5250\n",
            "Epoch 10/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.3181 - accuracy: 0.5290 - val_loss: 1.3135 - val_accuracy: 0.5372\n",
            "Epoch 11/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.2895 - accuracy: 0.5384 - val_loss: 1.2757 - val_accuracy: 0.5420\n",
            "Epoch 12/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 1.2644 - accuracy: 0.5501 - val_loss: 1.2420 - val_accuracy: 0.5575\n",
            "Epoch 13/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.2420 - accuracy: 0.5613 - val_loss: 1.2325 - val_accuracy: 0.5625\n",
            "Epoch 14/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.2213 - accuracy: 0.5696 - val_loss: 1.2099 - val_accuracy: 0.5688\n",
            "Epoch 15/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 1.2014 - accuracy: 0.5734 - val_loss: 1.1753 - val_accuracy: 0.5850\n",
            "Epoch 16/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.1783 - accuracy: 0.5847 - val_loss: 1.1494 - val_accuracy: 0.5910\n",
            "Epoch 17/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.1601 - accuracy: 0.5897 - val_loss: 1.1485 - val_accuracy: 0.5955\n",
            "Epoch 18/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.1423 - accuracy: 0.5980 - val_loss: 1.1361 - val_accuracy: 0.5985\n",
            "Epoch 19/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 1.1221 - accuracy: 0.6050 - val_loss: 1.1049 - val_accuracy: 0.6080\n",
            "Epoch 20/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 1.1044 - accuracy: 0.6128 - val_loss: 1.0767 - val_accuracy: 0.6227\n",
            "Epoch 21/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.0830 - accuracy: 0.6198 - val_loss: 1.0848 - val_accuracy: 0.6155\n",
            "Epoch 22/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.0693 - accuracy: 0.6243 - val_loss: 1.0413 - val_accuracy: 0.6390\n",
            "Epoch 23/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 1.0558 - accuracy: 0.6299 - val_loss: 1.0263 - val_accuracy: 0.6420\n",
            "Epoch 24/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 1.0362 - accuracy: 0.6377 - val_loss: 1.0121 - val_accuracy: 0.6503\n",
            "Epoch 25/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.0223 - accuracy: 0.6410 - val_loss: 1.0099 - val_accuracy: 0.6423\n",
            "Epoch 26/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 1.0083 - accuracy: 0.6463 - val_loss: 0.9901 - val_accuracy: 0.6475\n",
            "Epoch 27/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.9938 - accuracy: 0.6510 - val_loss: 0.9812 - val_accuracy: 0.6555\n",
            "Epoch 28/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.9761 - accuracy: 0.6573 - val_loss: 0.9569 - val_accuracy: 0.6578\n",
            "Epoch 29/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.9637 - accuracy: 0.6613 - val_loss: 0.9590 - val_accuracy: 0.6578\n",
            "Epoch 30/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.9505 - accuracy: 0.6677 - val_loss: 0.9365 - val_accuracy: 0.6708\n",
            "Epoch 31/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.9320 - accuracy: 0.6735 - val_loss: 0.9296 - val_accuracy: 0.6715\n",
            "Epoch 32/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.9243 - accuracy: 0.6762 - val_loss: 0.9263 - val_accuracy: 0.6743\n",
            "Epoch 33/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.9107 - accuracy: 0.6815 - val_loss: 0.9229 - val_accuracy: 0.6727\n",
            "Epoch 34/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.9026 - accuracy: 0.6842 - val_loss: 0.9038 - val_accuracy: 0.6852\n",
            "Epoch 35/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.8885 - accuracy: 0.6915 - val_loss: 0.9073 - val_accuracy: 0.6780\n",
            "Epoch 36/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.8779 - accuracy: 0.6926 - val_loss: 0.8806 - val_accuracy: 0.6877\n",
            "Epoch 37/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.8662 - accuracy: 0.6992 - val_loss: 0.8773 - val_accuracy: 0.6895\n",
            "Epoch 38/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.8559 - accuracy: 0.7012 - val_loss: 0.8716 - val_accuracy: 0.6963\n",
            "Epoch 39/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.8464 - accuracy: 0.7050 - val_loss: 0.8575 - val_accuracy: 0.6948\n",
            "Epoch 40/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.8341 - accuracy: 0.7094 - val_loss: 0.8384 - val_accuracy: 0.7070\n",
            "Epoch 41/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.8267 - accuracy: 0.7124 - val_loss: 0.8581 - val_accuracy: 0.7005\n",
            "Epoch 42/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.8108 - accuracy: 0.7180 - val_loss: 0.8295 - val_accuracy: 0.7107\n",
            "Epoch 43/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.8058 - accuracy: 0.7193 - val_loss: 0.8211 - val_accuracy: 0.7143\n",
            "Epoch 44/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.7922 - accuracy: 0.7259 - val_loss: 0.8202 - val_accuracy: 0.7107\n",
            "Epoch 45/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.7863 - accuracy: 0.7256 - val_loss: 0.8167 - val_accuracy: 0.7048\n",
            "Epoch 46/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.7756 - accuracy: 0.7279 - val_loss: 0.8064 - val_accuracy: 0.7150\n",
            "Epoch 47/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.7719 - accuracy: 0.7320 - val_loss: 0.8078 - val_accuracy: 0.7160\n",
            "Epoch 48/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.7581 - accuracy: 0.7354 - val_loss: 0.7899 - val_accuracy: 0.7185\n",
            "Epoch 49/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.7460 - accuracy: 0.7390 - val_loss: 0.7788 - val_accuracy: 0.7207\n",
            "Epoch 50/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.7374 - accuracy: 0.7436 - val_loss: 0.7824 - val_accuracy: 0.7228\n",
            "Epoch 51/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.7301 - accuracy: 0.7457 - val_loss: 0.7814 - val_accuracy: 0.7245\n",
            "Epoch 52/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.7236 - accuracy: 0.7485 - val_loss: 0.7856 - val_accuracy: 0.7212\n",
            "Epoch 53/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.7130 - accuracy: 0.7534 - val_loss: 0.7672 - val_accuracy: 0.7275\n",
            "Epoch 54/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.7077 - accuracy: 0.7543 - val_loss: 0.7861 - val_accuracy: 0.7230\n",
            "Epoch 55/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.6998 - accuracy: 0.7584 - val_loss: 0.7541 - val_accuracy: 0.7368\n",
            "Epoch 56/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.6940 - accuracy: 0.7586 - val_loss: 0.7655 - val_accuracy: 0.7320\n",
            "Epoch 57/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.6840 - accuracy: 0.7602 - val_loss: 0.7510 - val_accuracy: 0.7345\n",
            "Epoch 58/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.6742 - accuracy: 0.7653 - val_loss: 0.7392 - val_accuracy: 0.7333\n",
            "Epoch 59/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.6654 - accuracy: 0.7676 - val_loss: 0.7400 - val_accuracy: 0.7345\n",
            "Epoch 60/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.6587 - accuracy: 0.7727 - val_loss: 0.7444 - val_accuracy: 0.7393\n",
            "Epoch 61/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.6548 - accuracy: 0.7724 - val_loss: 0.7379 - val_accuracy: 0.7402\n",
            "Epoch 62/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.6467 - accuracy: 0.7750 - val_loss: 0.7246 - val_accuracy: 0.7393\n",
            "Epoch 63/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.6368 - accuracy: 0.7787 - val_loss: 0.7282 - val_accuracy: 0.7433\n",
            "Epoch 64/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.6284 - accuracy: 0.7822 - val_loss: 0.7161 - val_accuracy: 0.7498\n",
            "Epoch 65/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.6221 - accuracy: 0.7834 - val_loss: 0.7336 - val_accuracy: 0.7430\n",
            "Epoch 66/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.6132 - accuracy: 0.7890 - val_loss: 0.7062 - val_accuracy: 0.7513\n",
            "Epoch 67/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.6062 - accuracy: 0.7898 - val_loss: 0.7113 - val_accuracy: 0.7470\n",
            "Epoch 68/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.6014 - accuracy: 0.7922 - val_loss: 0.7096 - val_accuracy: 0.7505\n",
            "Epoch 69/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.5953 - accuracy: 0.7942 - val_loss: 0.7008 - val_accuracy: 0.7558\n",
            "Epoch 70/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.5862 - accuracy: 0.7976 - val_loss: 0.6992 - val_accuracy: 0.7495\n",
            "Baseline 정확률은 75.30999779701233\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 1, 1, 2048)        23587712  \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 1000)              2049000   \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 1000)              0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 500)               500500    \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 500)               0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 100)               50100     \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (None, 100)               0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,188,322\n",
            "Trainable params: 26,135,202\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n",
            "Epoch 1/70\n",
            "782/782 [==============================] - 100s 61ms/step - loss: 2.4235 - accuracy: 0.1675 - val_loss: 2.7598 - val_accuracy: 0.1370\n",
            "Epoch 2/70\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 1.8604 - accuracy: 0.3266 - val_loss: 1.4609 - val_accuracy: 0.5142\n",
            "Epoch 3/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 1.4694 - accuracy: 0.4896 - val_loss: 1.1655 - val_accuracy: 0.6045\n",
            "Epoch 4/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 1.2193 - accuracy: 0.5895 - val_loss: 0.9830 - val_accuracy: 0.6740\n",
            "Epoch 5/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 1.0374 - accuracy: 0.6573 - val_loss: 0.8889 - val_accuracy: 0.7070\n",
            "Epoch 6/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 0.8954 - accuracy: 0.7104 - val_loss: 0.8297 - val_accuracy: 0.7283\n",
            "Epoch 7/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 0.7815 - accuracy: 0.7490 - val_loss: 0.7772 - val_accuracy: 0.7520\n",
            "Epoch 8/70\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 0.6701 - accuracy: 0.7841 - val_loss: 0.7725 - val_accuracy: 0.7523\n",
            "Epoch 9/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 0.5821 - accuracy: 0.8133 - val_loss: 0.7750 - val_accuracy: 0.7623\n",
            "Epoch 10/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 0.4963 - accuracy: 0.8440 - val_loss: 0.7746 - val_accuracy: 0.7705\n",
            "Epoch 11/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 0.4216 - accuracy: 0.8662 - val_loss: 0.8077 - val_accuracy: 0.7700\n",
            "Epoch 12/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 0.3577 - accuracy: 0.8879 - val_loss: 0.8476 - val_accuracy: 0.7725\n",
            "Epoch 13/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 0.3053 - accuracy: 0.9045 - val_loss: 0.8881 - val_accuracy: 0.7730\n",
            "Epoch 14/70\n",
            "782/782 [==============================] - 46s 58ms/step - loss: 0.2606 - accuracy: 0.9197 - val_loss: 0.9402 - val_accuracy: 0.7665\n",
            "Epoch 15/70\n",
            "782/782 [==============================] - 46s 58ms/step - loss: 0.2257 - accuracy: 0.9307 - val_loss: 0.9420 - val_accuracy: 0.7705\n",
            "Epoch 16/70\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 0.1953 - accuracy: 0.9410 - val_loss: 0.9980 - val_accuracy: 0.7713\n",
            "Epoch 17/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 0.1713 - accuracy: 0.9492 - val_loss: 1.0245 - val_accuracy: 0.7720\n",
            "Epoch 18/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 0.1582 - accuracy: 0.9537 - val_loss: 1.0673 - val_accuracy: 0.7703\n",
            "Epoch 19/70\n",
            "782/782 [==============================] - 46s 58ms/step - loss: 0.1366 - accuracy: 0.9600 - val_loss: 1.0531 - val_accuracy: 0.7782\n",
            "Epoch 20/70\n",
            "782/782 [==============================] - 46s 58ms/step - loss: 0.1232 - accuracy: 0.9635 - val_loss: 1.0561 - val_accuracy: 0.7807\n",
            "Epoch 21/70\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 0.1058 - accuracy: 0.9690 - val_loss: 1.1322 - val_accuracy: 0.7810\n",
            "Epoch 22/70\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 0.0977 - accuracy: 0.9717 - val_loss: 1.1138 - val_accuracy: 0.7812\n",
            "Epoch 23/70\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 0.0950 - accuracy: 0.9730 - val_loss: 1.1209 - val_accuracy: 0.7803\n",
            "Epoch 24/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 0.0835 - accuracy: 0.9760 - val_loss: 1.1485 - val_accuracy: 0.7820\n",
            "Epoch 25/70\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 0.0810 - accuracy: 0.9770 - val_loss: 1.1883 - val_accuracy: 0.7775\n",
            "Epoch 26/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 0.0735 - accuracy: 0.9796 - val_loss: 1.2005 - val_accuracy: 0.7845\n",
            "Epoch 27/70\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 0.0656 - accuracy: 0.9821 - val_loss: 1.2413 - val_accuracy: 0.7840\n",
            "Epoch 28/70\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 0.0659 - accuracy: 0.9815 - val_loss: 1.2037 - val_accuracy: 0.7810\n",
            "Epoch 29/70\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 0.0627 - accuracy: 0.9821 - val_loss: 1.2171 - val_accuracy: 0.7815\n",
            "Epoch 30/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 0.0593 - accuracy: 0.9836 - val_loss: 1.2052 - val_accuracy: 0.7840\n",
            "Epoch 31/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 0.0588 - accuracy: 0.9839 - val_loss: 1.2628 - val_accuracy: 0.7788\n",
            "Epoch 32/70\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 0.0515 - accuracy: 0.9857 - val_loss: 1.2438 - val_accuracy: 0.7840\n",
            "Epoch 33/70\n",
            "782/782 [==============================] - 46s 58ms/step - loss: 0.0540 - accuracy: 0.9851 - val_loss: 1.2469 - val_accuracy: 0.7908\n",
            "Epoch 34/70\n",
            "782/782 [==============================] - 46s 58ms/step - loss: 0.0533 - accuracy: 0.9853 - val_loss: 1.2178 - val_accuracy: 0.7890\n",
            "Epoch 35/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 0.0477 - accuracy: 0.9866 - val_loss: 1.2433 - val_accuracy: 0.7880\n",
            "Epoch 36/70\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 0.0453 - accuracy: 0.9878 - val_loss: 1.2066 - val_accuracy: 0.7960\n",
            "Epoch 37/70\n",
            "782/782 [==============================] - 46s 58ms/step - loss: 0.0427 - accuracy: 0.9878 - val_loss: 1.2597 - val_accuracy: 0.7915\n",
            "Epoch 38/70\n",
            "782/782 [==============================] - 46s 58ms/step - loss: 0.0421 - accuracy: 0.9888 - val_loss: 1.2327 - val_accuracy: 0.7928\n",
            "Epoch 39/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 0.0359 - accuracy: 0.9899 - val_loss: 1.2415 - val_accuracy: 0.7930\n",
            "Epoch 40/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 0.0403 - accuracy: 0.9891 - val_loss: 1.2325 - val_accuracy: 0.7928\n",
            "Epoch 41/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 0.0373 - accuracy: 0.9897 - val_loss: 1.2506 - val_accuracy: 0.7897\n",
            "Epoch 42/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 0.0383 - accuracy: 0.9895 - val_loss: 1.2412 - val_accuracy: 0.7950\n",
            "Epoch 43/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 0.0350 - accuracy: 0.9900 - val_loss: 1.2668 - val_accuracy: 0.7893\n",
            "Epoch 44/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 0.0357 - accuracy: 0.9907 - val_loss: 1.2694 - val_accuracy: 0.7885\n",
            "Epoch 45/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 0.0381 - accuracy: 0.9895 - val_loss: 1.2341 - val_accuracy: 0.7915\n",
            "Epoch 46/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 0.0309 - accuracy: 0.9910 - val_loss: 1.2026 - val_accuracy: 0.7940\n",
            "Epoch 47/70\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 0.0303 - accuracy: 0.9915 - val_loss: 1.3228 - val_accuracy: 0.7937\n",
            "Epoch 48/70\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 0.0364 - accuracy: 0.9898 - val_loss: 1.2169 - val_accuracy: 0.7940\n",
            "Epoch 49/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 0.0296 - accuracy: 0.9919 - val_loss: 1.2738 - val_accuracy: 0.7947\n",
            "Epoch 50/70\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 0.0323 - accuracy: 0.9906 - val_loss: 1.2590 - val_accuracy: 0.7943\n",
            "Epoch 51/70\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 0.0293 - accuracy: 0.9917 - val_loss: 1.3128 - val_accuracy: 0.7997\n",
            "Epoch 52/70\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 0.0265 - accuracy: 0.9931 - val_loss: 1.2719 - val_accuracy: 0.7977\n",
            "Epoch 53/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 0.0280 - accuracy: 0.9921 - val_loss: 1.3136 - val_accuracy: 0.7933\n",
            "Epoch 54/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 0.0268 - accuracy: 0.9922 - val_loss: 1.2839 - val_accuracy: 0.7962\n",
            "Epoch 55/70\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 0.0253 - accuracy: 0.9929 - val_loss: 1.2944 - val_accuracy: 0.7968\n",
            "Epoch 56/70\n",
            "782/782 [==============================] - 46s 58ms/step - loss: 0.0263 - accuracy: 0.9929 - val_loss: 1.3372 - val_accuracy: 0.7970\n",
            "Epoch 57/70\n",
            "782/782 [==============================] - 46s 58ms/step - loss: 0.0253 - accuracy: 0.9931 - val_loss: 1.3112 - val_accuracy: 0.7965\n",
            "Epoch 58/70\n",
            "782/782 [==============================] - 46s 58ms/step - loss: 0.0249 - accuracy: 0.9932 - val_loss: 1.3155 - val_accuracy: 0.7962\n",
            "Epoch 59/70\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 0.0264 - accuracy: 0.9930 - val_loss: 1.2734 - val_accuracy: 0.7970\n",
            "Epoch 60/70\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 0.0260 - accuracy: 0.9937 - val_loss: 1.2290 - val_accuracy: 0.8002\n",
            "Epoch 61/70\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 0.0247 - accuracy: 0.9927 - val_loss: 1.2649 - val_accuracy: 0.7975\n",
            "Epoch 62/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 0.0209 - accuracy: 0.9943 - val_loss: 1.3268 - val_accuracy: 0.7945\n",
            "Epoch 63/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 0.0257 - accuracy: 0.9931 - val_loss: 1.3095 - val_accuracy: 0.7935\n",
            "Epoch 64/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 0.0219 - accuracy: 0.9938 - val_loss: 1.3304 - val_accuracy: 0.8015\n",
            "Epoch 65/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 0.0248 - accuracy: 0.9936 - val_loss: 1.2687 - val_accuracy: 0.7970\n",
            "Epoch 66/70\n",
            "782/782 [==============================] - 46s 58ms/step - loss: 0.0250 - accuracy: 0.9933 - val_loss: 1.2666 - val_accuracy: 0.8043\n",
            "Epoch 67/70\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 0.0164 - accuracy: 0.9954 - val_loss: 1.3898 - val_accuracy: 0.8000\n",
            "Epoch 68/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 0.0234 - accuracy: 0.9937 - val_loss: 1.3260 - val_accuracy: 0.8010\n",
            "Epoch 69/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 0.0230 - accuracy: 0.9937 - val_loss: 1.3203 - val_accuracy: 0.7995\n",
            "Epoch 70/70\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 0.0185 - accuracy: 0.9948 - val_loss: 1.3108 - val_accuracy: 0.8015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-13-8ceb2434d4bf>:117: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline vs yours:  75.30999779701233 80.84999918937683\n",
            "TF 2.12.0 under GPU True\n",
            "python version 3.9.16 (main, Dec  7 2022, 01:11:51) \n",
            "[GCC 9.4.0]\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1Py2GvZc1GwqNbrR4fuQrHFy6zBEdF1xF\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten,Dense,BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import os\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "\n",
        "(x_train,y_train),(x_test,y_test)=cifar10.load_data()\n",
        "x_train=x_train.astype(np.float32)/255.0\n",
        "y_train=tf.keras.utils.to_categorical(y_train,10)\n",
        "\n",
        "x_test=x_test.astype(np.float32)/255.0\n",
        "y_test=tf.keras.utils.to_categorical(y_test,10)\n",
        "\n",
        "x_val, _, y_val,_ = train_test_split(x_test, y_test, test_size=0.6, random_state=1)\n",
        "\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "g_epoch = 70\n",
        "g_batch = 64\n",
        "\n",
        "def reset_random_seeds():\n",
        "   os.environ['PYTHONHASHSEED']=str(1)\n",
        "   tf.random.set_seed(1)\n",
        "   np.random.seed(1)\n",
        "   random.seed(1)\n",
        "   os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "\n",
        "reset_random_seeds() \n",
        "   \n",
        "print(\"reduced train/val size:\", len(x_train), len(x_val), \"input shape:\", input_shape)\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "\n",
        "tf.__version__\n",
        "\n",
        "from tensorflow.keras.layers import MaxPooling2D, Dropout, Conv2D\n",
        "\n",
        "cnn=Sequential()\n",
        "cnn.add(Conv2D(64,(3,3),activation='relu',input_shape=(32,32,3)))\n",
        "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
        "cnn.add(Dropout(0.25))\n",
        "cnn.add(Conv2D(128,(3,3),activation='relu', padding='same'))\n",
        "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
        "cnn.add(Dropout(0.25))\n",
        "cnn.add(Conv2D(256,(3,3),activation='relu', padding='same'))\n",
        "cnn.add(Conv2D(256,(3,3),activation='relu', padding='same'))\n",
        "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(1000,activation='relu'))\n",
        "cnn.add(Dropout(0.5))\n",
        "cnn.add(Dense(10,activation='softmax'))\n",
        "\n",
        "cnn.compile(loss='categorical_crossentropy',optimizer=Adam(0.00002),metrics=['accuracy'])\n",
        "cnn.summary()\n",
        "\n",
        "hist=cnn.fit(x_train, y_train, batch_size=g_batch, epochs=g_epoch,\n",
        "             validation_data=(x_val,y_val), verbose=1)\n",
        "\n",
        "g_org_res=cnn.evaluate(x_test,y_test,verbose=0)\n",
        "print(\"Baseline 정확률은\",g_org_res[1]*100)\n",
        "\n",
        "no_class = 10\n",
        "\n",
        "\n",
        "# for transfer learning only\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "\n",
        "os.environ['PYTHONHASHSEED']=str(1)\n",
        "tf.random.set_seed(1)\n",
        "np.random.seed(1)\n",
        "random.seed(1)\n",
        "\n",
        "# for transfer learning only\n",
        "transfermodel = ResNet50(weights='imagenet',include_top=False,\n",
        "                    input_shape=input_shape)\n",
        "#base_model.trainable=False     # it's up to you\n",
        "\n",
        "# your model architecture\n",
        "model=Sequential()\n",
        "# 전처리 레이어 추가/변경 가능\n",
        "model.add(transfermodel)    # for transfer learning only\n",
        "model.add(Flatten())        # for transfer learning only\n",
        "model.add(Dense(1000,activation='relu')) # <<-- 변경가능\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(500,activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(100,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(no_class, activation='softmax')) # <<-- activation은 변경가능\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer=Adam(0.00002),metrics=['accuracy']) # <<-- 변경가능\n",
        "model.summary()\n",
        "\n",
        "hist=model.fit(x_train, y_train, batch_size=g_batch, epochs=g_epoch,\n",
        "             validation_data=(x_val,y_val), verbose=1)\n",
        "\n",
        "yours=model.evaluate(x_test,y_test,verbose=0)\n",
        "print(\"Baseline vs yours: \",g_org_res[1]*100, yours[1]*100)\n",
        "\n",
        "\n",
        "print('TF {0} under GPU {1}'.format(\n",
        "    tf.__version__, tf.test.is_gpu_available()))\n",
        "import sys\n",
        "print(\"python version\", sys.version)"
      ]
    }
  ]
}